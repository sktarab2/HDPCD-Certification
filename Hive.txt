1) Create a hive managed table 


CREATE DATABASE IF NOT EXISTS cards;

CREATE TABLE deck_of_cards (
COLOR string,
SUIT string,
PIP string)
ROW FORMAT DELIMITED FIELDS TERMINATED BY '|'
STORED AS TEXTFILE;

2) Load data from local file system into hive table (append to existing table)

LOAD DATA LOCAL INPATH '/root/demo/data/cards/deckofcards.txt' INTO TABLE deck_of_cards;

3) Load data from HDFS into hive table (append data to existing table)  --file user /user/root/cards will be deleted

LOAD DATA INPATH '/user/root/cards/deckofcards.txt' INTO TABLE deck_of_cards;

4) Loads data from local file system (overwrite existing data)

LOAD DATA LOCAL INPATH '/root/demo/data/cards/deckofcards.txt' OVERWRITE INTO TABLE deck_of_cards;

5) Create a Hive external table

CREATE EXTERNAL TABLE deck_of_cards_external (
COLOR string,
SUIT string,
PIP string)
ROW FORMAT DELIMITED FIELDS TERMINATED BY '|'
STORED AS TEXTFILE
LOCATION '/apps/hive/warehouse/cards.db/deck_of_cards';

-- Create ods and edw database for retail_db@mysql
-- CREATE DATABASE IF NOT EXISTS retail_ods;
-- CREATE DATABASE retail_edw;
-- CREATE DATABASE retail_stage;

6) Define a Hive-managed table 

USE retail_stage;
CREATE TABLE orders_demo (
order_id int,
order_date string,
order_customer_id int,
order_status string
)
ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
STORED AS TEXTFILE;

CREATE TABLE categories (
category_id int,
category_department_id int,
category_name string
)
ROW FORMAT DELIMITED FIELDS TERMINATED BY '|'
STORED AS TEXTFILE;

CREATE TABLE customers (
customer_id       int,
customer_fname    string,
customer_lname    string,
customer_email    string,
customer_password string,
customer_street   string,
customer_city     string,
customer_state    string,
customer_zipcode  string 
)
ROW FORMAT DELIMITED FIELDS TERMINATED BY '|'
STORED AS TEXTFILE;

CREATE TABLE departments (
department_id int,
department_name string
)
ROW FORMAT DELIMITED FIELDS TERMINATED BY '|'
STORED AS TEXTFILE;

7) Load data from local file system to hive table

load data local inpath '/tmp/categories01.psv' overwrite into table categories;
load data local inpath '/tmp/customers.psv' overwrite into table customers;
load data local inpath '/tmp/departments.psv' overwrite into table departments;
load data local inpath '/tmp/products.psv' overwrite into table products;

8) Load data from HDFS to hive table

load data inpath '/tmp/categories01.psv' overwrite into table categories;
load data inpath '/tmp/customers.psv' overwrite into table customers;
load data inpath '/tmp/departments.psv' overwrite into table departments;
load data inpath '/tmp/products.psv' overwrite into table products;


9) Get number of orders by order_status for a given date '2013-12-14'

SELECT order_status, count(1) FROM orders
WHERE order_date = '2013-12-14 00:00:00.0'
GROUP BY order_status
ORDER BY order_status;

10) Get number of completed orders for each date before '2013-12-14 00:00:00.0'

SELECT order_date, count(1) FROM orders
WHERE order_date <= '2013-12-14 00:00:00.0' AND order_status = 'COMPLETE'
GROUP BY order_date
ORDER BY order_date;

11) Get number of pending, review and onhold order for each date for the month of 2013 December

SELECT order_date, count(1) FROM orders
WHERE order_date LIKE '2013-12%' AND order_status IN ('PENDING', 'PENDING_PAYMENT', 'PAYMENT_REVIEW', 'ON_HOLD')
-- order_date LIKE '2013-12%' AND (order_status = 'PENDING' or order_status = 'PENDING_PAYMENT'....)
GROUP BY order_date
ORDER BY order_date;

12) Hive transactions

set hive.txn.manager by default it uses DummyTxnManager;
set hive.txn.manager=org.apache.hadoop.hive.ql.lockmgr.DbTxnManager;


-- Creating table
-- Make sure table is bucketed, file format is orc and 
-- transactional is set to true under tblproperties
create table hive_transactions (i int, j string)
clustered by (i) into 4 buckets
stored as orc
tblproperties ('transactional'='true');

-- Inserting data
insert into table hive_transactions values (1, 'itversity');
insert into table hive_transactions values (2, 'itversity');

--or insert into table hive_transactions (i, j) values (1, 'itversity');

-- Updating data
update hive_transactions set j = 'IT Versity' where i = 2;

-- Deleting data
delete hive_transactions where i = 1;


13) Create a Partitioned table 

CREATE table orders_partitioned
(order_id int,
order_date string,
order_customer_id int,
order_status string)
PARTITIONED BY (order_month string)
ROW FORMAT DELIMITED 
FIELDS TERMINATED BY ','
STORED AS TEXTFILE;

14) Create a partition manually

ALTER TABLE orders_partitioned ADD PARTITION (order_month='2014-01');

15) Inserting data into a partitioned table dynamically and automatically

INSERT INTO orders_partitioned PARTITION(order_month string)
SELECT order_id,substr((order_date),1,10) order_date,order_customer_id,order_status,substr((order_date),1,7) order_month 
from orders;

16) Inserting data manually for each partition 


INSERT INTO orders_partitioned PARTITION(order_month='2014-01')
SELECT order_id,substr((order_date),1,10) order_date,order_customer_id,order_status,substr((order_date),1,7) order_month 
from orders where order_date='2014-01';

17) Creating a bucketed table 

CREATE table orders_bucketed
(order_id int,
order_date string,
order_customer_id int,
order_status string)
CLUSTERED BY (order_id) INTO 16 buckets
ROW FORMAT DELIMITED 
FIELDS TERMINATED BY ','
STORED AS ORC;

18) Inserting data into a bucketed table

INSERT INTO TABLE orders_bucketed
SELECT * FROM orders
where order_id<150;





